{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc2b2a86",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-21T07:00:07.579885Z",
     "iopub.status.busy": "2025-09-21T07:00:07.579537Z",
     "iopub.status.idle": "2025-09-21T07:01:45.803901Z",
     "shell.execute_reply": "2025-09-21T07:01:45.801733Z"
    },
    "papermill": {
     "duration": 98.230378,
     "end_time": "2025-09-21T07:01:45.806425",
     "exception": false,
     "start_time": "2025-09-21T07:00:07.576047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\r\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets soundfile accelerate huggingface_hub resampy torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "279ddd96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T07:01:45.863700Z",
     "iopub.status.busy": "2025-09-21T07:01:45.862429Z",
     "iopub.status.idle": "2025-09-21T07:01:47.052108Z",
     "shell.execute_reply": "2025-09-21T07:01:47.050824Z"
    },
    "papermill": {
     "duration": 1.220573,
     "end_time": "2025-09-21T07:01:47.054617",
     "exception": false,
     "start_time": "2025-09-21T07:01:45.834044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'processed_samples.json': No such file or directory\r\n",
      "rm: cannot remove 'processing_log.txt': No such file or directory\r\n",
      "Cloning into 'Kaggle_thesis_files'...\r\n",
      "remote: Enumerating objects: 88, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (88/88), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (88/88), done.\u001b[K\r\n",
      "remote: Total 88 (delta 53), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (88/88), 37.30 KiB | 3.73 MiB/s, done.\r\n",
      "Resolving deltas: 100% (53/53), done.\r\n"
     ]
    }
   ],
   "source": [
    "%rm -rf Kaggle_thesis_files\n",
    "%rm processed_samples.json processing_log.txt\n",
    "!git clone https://github.com/deep-reason/Kaggle_thesis_files.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b7943ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T07:01:47.116651Z",
     "iopub.status.busy": "2025-09-21T07:01:47.116201Z",
     "iopub.status.idle": "2025-09-21T07:01:58.721848Z",
     "shell.execute_reply": "2025-09-21T07:01:58.720506Z"
    },
    "papermill": {
     "duration": 11.637013,
     "end_time": "2025-09-21T07:01:58.723741",
     "exception": false,
     "start_time": "2025-09-21T07:01:47.086728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/Kaggle_thesis_files/normalize_and_resample_HF_finetune_dataset.py\", line 42, in <module>\r\n",
      "    raise ValueError(\"HF_TOKEN environment variable is not set. Please set your Hugging Face token as a Kaggle Secret.\")\r\n",
      "ValueError: HF_TOKEN environment variable is not set. Please set your Hugging Face token as a Kaggle Secret.\r\n"
     ]
    }
   ],
   "source": [
    "!python Kaggle_thesis_files/normalize_and_resample_HF_finetune_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668d667c",
   "metadata": {
    "papermill": {
     "duration": 0.027149,
     "end_time": "2025-09-21T07:01:58.778466",
     "exception": false,
     "start_time": "2025-09-21T07:01:58.751317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 117.144877,
   "end_time": "2025-09-21T07:01:59.328030",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-21T07:00:02.183153",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
